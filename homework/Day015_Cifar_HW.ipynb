{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\andy\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.3787 - acc: 0.5518\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.7635 - acc: 0.7348\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.4983 - acc: 0.8270\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.3060 - acc: 0.8940\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1882 - acc: 0.9352\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1451 - acc: 0.9509\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.1369 - acc: 0.9526\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.1202 - acc: 0.9594\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0927 - acc: 0.9686\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0852 - acc: 0.9709\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0862 - acc: 0.9709\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0791 - acc: 0.9727\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0650 - acc: 0.9777\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0616 - acc: 0.9795\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0581 - acc: 0.9809\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0530 - acc: 0.9819\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0595 - acc: 0.9812\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0643 - acc: 0.9790\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0505 - acc: 0.9837\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0385 - acc: 0.9873\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0404 - acc: 0.9867\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0437 - acc: 0.9860\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0536 - acc: 0.9827\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0450 - acc: 0.9852\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0272 - acc: 0.9909\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0362 - acc: 0.9876\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0370 - acc: 0.9882\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0354 - acc: 0.9880\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0335 - acc: 0.9894\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0390 - acc: 0.9877\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0293 - acc: 0.9905\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0267 - acc: 0.9911\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0265 - acc: 0.9916\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0300 - acc: 0.9904\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0340 - acc: 0.9892\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0301 - acc: 0.9905\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0246 - acc: 0.9920\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0201 - acc: 0.9934\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0321 - acc: 0.9901\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0273 - acc: 0.9914\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0278 - acc: 0.9913\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0274 - acc: 0.9912\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0208 - acc: 0.9934\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0217 - acc: 0.9934\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0239 - acc: 0.9930\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0278 - acc: 0.9919\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0198 - acc: 0.9935\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0231 - acc: 0.9932\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0175 - acc: 0.9943\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0204 - acc: 0.9937\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0220 - acc: 0.9935\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0212 - acc: 0.9937\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0231 - acc: 0.9934\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0204 - acc: 0.9935\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0175 - acc: 0.9954\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0173 - acc: 0.9948\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0161 - acc: 0.9952\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 73s 1ms/step - loss: 0.0256 - acc: 0.9925\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0161 - acc: 0.9952\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0156 - acc: 0.9954\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0198 - acc: 0.9941\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0201 - acc: 0.9942\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 0.0198 - acc: 0.9946\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0143 - acc: 0.9959\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0109 - acc: 0.9963\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 0.0135 - acc: 0.9957\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0167 - acc: 0.9948\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0154 - acc: 0.9956\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0152 - acc: 0.9958\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0107 - acc: 0.9964\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0156 - acc: 0.9956\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0178 - acc: 0.9947\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0162 - acc: 0.9952\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0139 - acc: 0.9959\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0139 - acc: 0.9962\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0145 - acc: 0.9959\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0164 - acc: 0.9957\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0144 - acc: 0.9960\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0151 - acc: 0.9957\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 0.0140 - acc: 0.9959\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0133 - acc: 0.9962\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0104 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0109 - acc: 0.9970\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0188 - acc: 0.9946\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0129 - acc: 0.9964\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 0.0114 - acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2449486af88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3),activation='relu'))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(64,3,3,activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3929196e-07, 4.4467631e-29, 2.8003423e-14, 9.9999988e-01,\n",
       "        4.7546416e-20, 7.5478982e-18, 4.7716720e-18, 2.7945375e-25,\n",
       "        5.7229504e-10, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
